<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>zijun</title>

    <meta name="author" content="Zijun Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="images/cat.png">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Zijun Wang
                </p>
                <p>
                  I am a second-year PhD student at <a href="https://www.ucsc.edu/">University of California, Santa Cruz</a> (UCSC), and my advisor is <a href="https://cihangxie.github.io/">Prof. Cihang Xie</a>. 
                  <!-- I am also fortunate to be interning with <a href="https://cihangxie.github.io/">Prof. Cihang Xie</a> at the <a href="https://www.ucsc.edu/"> University of California, Santa Cruz</a>. -->
                  I received my BS from <a href="https://www.zju.edu.cn/english/">Zhejiang University</a>.
                </p>
                <p>
                  My research interests mainly revolve around <a href="https://www.mlsafety.org/">AI Safety</a> / Text Generation <a href="https://huggingface.co/tasks/text-generation">[1]</a><a href="https://huggingface.co/tasks/image-text-to-text">[2]</a>.
                  <!-- , Natural Language Processing (NLP), Multi-modal learning and their applications.  -->
                </p>
                <!-- <p>
                  Specifically, I'm now working on Adversarial Attacks on LLMs & VLLMs.
                </p> -->
                <p>
                  <!-- <span class="highlight"> -->
                  <span>
                    I am always open to research discussions and collaborations : ) 
                  </span>
                </p>
                <p style="text-align:center">
                  <a href="mailto:zwang745@ucsc.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=n5wjgV0AAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/asillycat">Github</a> &nbsp;/&nbsp;
                  <a href="data/Resume_Zijun_251124.pdf">CV</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://twitter.com/zijun_wang2002">Twitter</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/zijun2.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/zijun2.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>News</h2>
                  <p>
                    [Nov. 2025] <a href="https://arxiv.org/abs/2504.01903">STAR-1</a> is accepted by <strong>AAAI 2026 (<em style="color: red;">oral</em>)</strong>
                  </p>
                  <p>
                    [Jun. 2025] I'm joining <a href="https://www.tiktok.com/about?lang=en">TikTok</a> as <a href="https://lifeattiktok.com/search/7564088059246512389">Research Scientist Intern</a>.
                  </p>
                  <p>
                    [Jan. 2025] <a href="https://arxiv.org/abs/2410.09040">AttnGCG</a> is accepted by <strong>TMLR 2025</strong>
                  </p>
                  <p>
                    [Dec. 2024] One paper is accepted by <strong>KDD 2025</strong>
                  </p>
                  <p>
                    [Jul. 2024] One paper is accepted by <strong>ECCV 2024</strong>
                  </p>
                  <p>
                    [Dec. 2023] <strong>Second Place</strong> in both base & large model subtracks of Red Teaming LLM@<strong>NeurIPS 2023, Torjan Detection Challenge</strong>
                  </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Selected Publications</h2>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
            <!-- <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()"  bgcolor="#ffffd0"> -->
              
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle;text-align:center">
                    <div><img src='images/paper_cover/SART1_teaser_final.jpg' width="250"></div>
                </td>
                <td width="75%" valign="middle">
                    <p>
                      <strong>STAR-1: Safer Alignment of Reasoning LLMs with 1K Data</strong>
                    <br>
                        <strong><a href="https://scholar.google.com/citations?user=n5wjgV0AAAAJ&hl=en">Zijun Wang</a></strong>, 
                        <a href="https://scholar.google.com/citations?user=hyFMd54AAAAJ&hl=en">Haoqin Tu</a>,
                        <a href="https://scholar.google.com/citations?user=Bo9xeqMAAAAJ&hl=en">Yuhan Wang</a>,
                        <a href="https://scholar.google.com/citations?user=RSn2gykAAAAJ&hl=en">Juncheng Wu</a>,
                        <a href="https://scholar.google.com/citations?user=2obvvPoAAAAJ&hl=en">Yanqing Liu</a>,
                        <a href="https://scholar.google.com/citations?user=nHKExN0AAAAJ&hl=en">Jieru Mei</a>,
                        <a href="https://scholar.google.com/citations?user=YdiZoJgAAAAJ&hl=en">Brian R. Bartoldson</a>,
                        <a href="https://scholar.google.com/citations?user=SQpJmOgAAAAJ&hl=en">Bhavya Kailkhura</a>,
                        <a href="https://scholar.google.com/citations?user=X3vVZPcAAAAJ&hl=en">Cihang Xie</a>,
                    <br>
                    <em>AAAI 2026</em> (<em style="color: red;">oral</em>)
                    <br>
                    </p>
                    <div class="paper" id="wang2025star1">
                        <a href="https://arxiv.org/abs/2504.01903">paper</a> /
                        <a href="https://ucsc-vlaa.github.io/STAR-1/">project page</a> /
                        <a href="https://github.com/UCSC-VLAA/STAR-1">code</a> /
                        <a href="https://huggingface.co/datasets/UCSC-VLAA/STAR-1">dataset</a> /
                        <a href="https://huggingface.co/collections/UCSC-VLAA/star-1">models</a>                    
                    </div>
                    <br>
                </td>
              </tr> 

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle;text-align:center">
                    <div><img src='images/paper_cover/mira.jpeg' width="150"></div>
                </td>
                <td width="75%" valign="middle">
                    <p>
                      <strong>When Visualizing is the First Step to Reasoning: MIRA, a
Benchmark for Visual Chain-of-Thought</strong>
                    <br>
                        <a href="https://scholar.google.com/citations?user=6KltFMAAAAAJ&hl=en">Yiyang Zhou*</a>,
                        <a href="https://scholar.google.com/citations?user=hyFMd54AAAAJ&hl=en">Haoqin Tu*</a>,
                        <strong><a href="https://scholar.google.com/citations?user=n5wjgV0AAAAJ&hl=en">Zijun Wang</a></strong>, 
                        <a href="https://scholar.google.com/citations?user=5uSmucsAAAAJ&hl=en">Zeyu Wang</a>,
                        <a href="https://scholar.google.com/citations?user=Me0IoRMAAAAJ&hl=en">Niklas Muennighoff</a>,
                        <a href="https://scholar.google.com/citations?user=o2lsU8YAAAAJ&hl=en">Fan Nie</a>,
                        <a href="https://scholar.google.com/citations?user=vhP-tlcAAAAJ&hl=en">Yejin Choi</a>,
                        <a href="https://scholar.google.com/citations?user=23ZXZvEAAAAJ&hl=en">James Zou</a>,
                        <a href="https://scholar.google.com/citations?user=k0TWfBoAAAAJ&hl=en">Chaorui Deng</a>,
                        <a href="https://scholar.google.com/citations?user=-shYRd8AAAAJ&hl=en">Shen Yan</a>,
                        <a href="https://scholar.google.com/citations?user=76B8lrgAAAAJ&hl=en">Haoqi Fan</a>,
                        <a href="https://scholar.google.com/citations?user=X3vVZPcAAAAJ&hl=en">Cihang Xie</a>,
                        <a href="https://scholar.google.com/citations?user=A20BZnQAAAAJ&hl=en">Huaxiu Yao</a>,
                        <a href="https://scholar.google.com/citations?user=ZYOhaGwAAAAJ&hl=zh-CN">Qinghao Ye</a>,
                        <br>
                    <em>Arxiv 2025</em>
                    <br>
                    </p>
                    <div class="paper" id="wang2025star1">
                        <a href="https://arxiv.org/abs/2511.02779">paper</a> /
                        <a href="https://mira-benchmark.github.io/">project page</a> /
                        <a href="https://github.com/aiming-lab/MIRA">code</a> /
                        <a href="https://huggingface.co/datasets/YiyangAiLab/MIRA">dataset</a>
                    <br>
                </td>
              </tr> 

              <tr>
                <td style="padding:20px;width:35%;vertical-align:middle;text-align:center">
                    <div><img src='images/paper_cover/attngcg_teaser.png' width="250"></div>
                </td>
                <td width="75%" valign="middle">
                    <p>
                      <strong>AttnGCG: Enhancing Jailbreaking Attacks on LLMs with Attention Manipulation</strong>
                    <br>
                        <strong><a href="https://scholar.google.com/citations?user=n5wjgV0AAAAJ&hl=en">Zijun Wang</a></strong>, 
                        <a href="https://scholar.google.com/citations?user=hyFMd54AAAAJ&hl=en">Haoqin Tu</a>,
                        <a href="https://scholar.google.com/citations?user=nHKExN0AAAAJ&hl=en">Jieru Mei</a>,
                        <a href="https://scholar.google.com/citations?user=lEcqFJEAAAAJ&hl=en">Bingchen Zhao</a>,
                        <a href="https://scholar.google.com/citations?user=uMWPDboAAAAJ&hl=en">Yisen Wang</a>,
                        <a href="https://scholar.google.com/citations?user=X3vVZPcAAAAJ&hl=en">Cihang Xie</a>,
                    <br>
                    <em>TMLR 2025</em>
                    <br>
                    </p>
                    <div class="paper" id="wang2024attngcg">
                        <a href="https://arxiv.org/abs/2410.09040">paper</a> /
                        <a href="https://github.com/UCSC-VLAA/AttnGCG-attack">code</a>
                    </div>
                    <br>
                </td>
              </tr> 
              
            <tr>
              <td style="padding:20px;width:35%;vertical-align:middle;text-align:center">
                  <div><img src='images/paper_cover/vllm_safety.jpg' width="250"></div>
              </td>
              <td width="75%" valign="middle">
                <p>
                  <strong>How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for Vision LLMs</strong>
                  <br>
                  <a href="https://scholar.google.com/citations?user=hyFMd54AAAAJ&hl=en">Haoqin Tu*</a>,
                  <a href="https://scholar.google.com/citations?user=V5X1gdAAAAAJ&hl=en">Chenhang Cui*</a>, 
                  <strong><a href="https://scholar.google.com/citations?user=n5wjgV0AAAAJ&hl=en">Zijun Wang*</a></strong>, 
                  <a href="https://scholar.google.com/citations?user=6KltFMAAAAAJ&hl=en">Yiyang Zhou,</a> 
                  <a href="https://scholar.google.com/citations?user=lEcqFJEAAAAJ&hl=en">Bingchen Zhao</a>, 
                  <a href="https://scholar.google.com/citations?user=5L0Uj_IAAAAJ&hl=en">Junlin Han</a>, 
                  <a href="https://scholar.google.com/citations?user=UebIjuQAAAAJ&hl=en">Wangchunshu Zhou</a>, 
                  <a href="https://scholar.google.com/citations?user=A20BZnQAAAAJ&hl=en">Huaxiu Yao</a>, 
                  <a href="https://scholar.google.com/citations?user=X3vVZPcAAAAJ&hl=en">Cihang Xie</a>
                  (* represents equal contribution)
                  <br>
                  <em>ECCV 2024</em>
                  <br>
                </p>
                <div class="paper" id="tu2023unicornsimagesafetyevaluation">
                    <a href="https://arxiv.org/abs/2311.16101">paper</a> /
                    <a href="https://github.com/UCSC-VLAA/vllm-safety-benchmark">code</a>
                </div>
                <br>
              </td>
            </tr> 

            <tr>
              <td style="padding:20px;width:35%;vertical-align:middle;text-align:center">
                  <div><img src='images/paper_cover/graph_patch.jpg' width="250"></div>
              </td>
              <td width="75%" valign="middle">
                <p>
                  <strong>Handling Feature Heterogeneity with Learnable Graph Patches</strong>
                  <br>
                  <a href="https://scholar.google.com/citations?user=9mxdFawAAAAJ">Yifei Sun</a>,
                  <a href="https://scholar.google.com/citations?user=C7UqPnoAAAAJ&hl=en">Yang Yang</a>, 
                  <a href="https://github.com/functionendless">Xiao Feng</a>, 
                  <strong><a href="https://scholar.google.com/citations?user=n5wjgV0AAAAJ&hl=en">Zijun Wang</a></strong>,
                  <a href="https://github.com/squarewhiteflag">Haoyang Zhong</a>, 
                  <a href="https://scholar.google.com/citations?user=Rmy5RogAAAAJ">Chunping Wang</a>, 
                  <a href="https://scholar.google.com.hk/citations?user=wDG2dMYAAAAJ&hl=en">Lei Chen</a>
                  <br>
                  <em>KDD</em>, 2025
                  <br>
                </p>
                <div class="paper" id="sun2024graphpatches">
                    <a href="http://yangy.org/works/gnn/KDD25_GraphPatches.pdf">paper</a> /
                    <a href="https://github.com/Sunefei/PatchNet">code</a>
                </div>
                <br>
              </td>
            </tr> 

              <!-- <tr bgcolor="#ffffd0"> -->
            <!-- <tr>
              <td style="padding:20px;width:35%;vertical-align:middle">
                  <img src='images/coming_soon.jpg' width="250"></div>
              </td>
              <td width="75%" valign="middle">
                  <p>
                    <strong>Handling Feature Heterogeneity with Learnable Graph Patches</strong>
                  <br>
                      <a href="https://scholar.google.com/citations?user=9mxdFawAAAAJ">Yifei Sun</a>,
                      <strong>Zijun Wang</strong>,
                      Xiao Feng,
                      <a href="https://scholar.google.com/citations?hl=zh-CN&user=Rmy5RogAAAAJ">Chunping Wang</a>,
                      <a href="https://scholar.google.com.hk/citations?user=wDG2dMYAAAAJ&hl=zh-CN">Lei CHEN</a>, 
                      <a href="https://scholar.google.com/citations?user=C7UqPnoAAAAJ&hl=en">Yang Yang</a>
                  <br>
                  <em>Technique Report</em>, 2023
                  <br>
                  </p>
                  <div class="paper" id="sun2023">
                      paper (coming soon) /
                      code (coming soon)
                  </div>
                  <br>
              </td>
            </tr>  -->

          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Experience</h2>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
            <!-- <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()"  bgcolor="#ffffd0"> -->
              
            <tr>
              <td style="text-align:center;width:30%;vertical-align:middle;text-align:center">
                  <img src='images/logo/UCSC_icon.png' width="80"></div>
              </td>
              <td width="75%" valign="middle">
                <p>
                  <strong>Sep. 2024 - Present, VLAA Lab, UC Santa Cruz</strong>
                </p>
                <p>
                  PhD student advised by <a href="https://cihangxie.github.io/">Prof. Cihang Xie</a>, AI Safety
                </p>
                <p>
                  <strong>Aug. 2023 - Aug. 2024, VLAA Lab, UC Santa Cruz</strong>
                </p>
                <p>
                  Visiting Research Intern advised by <a href="https://cihangxie.github.io/">Prof. Cihang Xie</a>, Adversarial Attacks on LLMs & VLLMs
                </p>
              </td>
            </tr> 

              <!-- <tr bgcolor="#ffffd0"> -->
            <tr>
              <td style="text-align:center;width:30%;vertical-align:middle;text-align:center">
                  <img src='images/logo/Zhejiang_University_Logo.svg.png' width="80"></div>
              </td>
              <td width="75%" valign="middle">
                <p>
                  <strong>Jan. 2023 - Jul. 2023, Zhejiang University</strong>
                </p>
                <p>
                  Research Assistant advised by Prof. Yang Yang, Genaralized Graph Pre-training
                </p>
                <p>
                  <strong>Sep. 2020 - Jun. 2024, Zhejiang University</strong>
                </p>
                <p>
                  Undergrad, GPA: 3.92/4.0
                </p>
              </td>
            </tr> 

          </tbody></table>

          
          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Academic Service</h2>
                  <p>
                      Conference Reviewer: NeruIPS2023
                  </p>
                  <p>
                      Journal Reviewer: TMLR
                  </p>
              </td>
            </tr>
          </tbody></table> -->

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Awards</h2>
                  <p>
                    -  <strong>National Scholarship</strong> issued by Ministry of Education of the People's Republic of China
                  </p>
                  <p>
                    -  <strong>First-class Scholarship</strong> of Zhejiang University 
                  </p>
                  <p>
                    -  <strong>Provincial Government Scholarship</strong> of Zhejiang Province
                  </p>
              </td>
            </tr>
          </tbody></table>

          <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=294&t=tt&d=np6cBe6AsfI_APXRpO4mpaAN6HHUJ7ZSogDPWivWnYE&co=0a7bcc&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Last Update 2025.01.24. Thanks to <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        
        </td>
      </tr>
    </table>
  </body>

</html>

